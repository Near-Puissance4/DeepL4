# DeepL4

## **Description**
Ce composant impl√©mente une intelligence artificielle capable d'apprendre √† jouer au Puissance 4 en utilisant l'**apprentissage par renforcement**. L'IA s'entra√Æne en jouant contre elle-m√™me et contre d'autres adversaires, am√©liorant progressivement ses d√©cisions gr√¢ce √† une fonction de r√©compense.

## **Technologies Utilis√©es**
- **Langage** : Python 3.x
- **Frameworks et Biblioth√®ques** :
  - TensorFlow / PyTorch (pour DQN si utilis√©)
  - NumPy (calculs matriciels)
  - Gym/OpenAI (facultatif, pour l'environnement d'entra√Ænement)
  - FastAPI (si API pour interaction avec le backend)

## **Architecture**
Le composant IA Apprentissage suit une approche bas√©e sur **Q-Learning** ou **Deep Q-Networks (DQN)**.

### **Sch√©ma g√©n√©ral**
```plaintext
[Backend (NestJS)] <----> [IA Apprentissage (Python)]
```
L'IA re√ßoit la grille actuelle et retourne le meilleur coup √† jouer.

### **Composants principaux**
1. **Agent d'apprentissage** : prend des d√©cisions et met √† jour ses connaissances.
2. **Environnement de jeu** : repr√©sente la grille et applique les r√®gles du Puissance 4.
3. **M√©moire d'exp√©rience** : stocke les parties pour entra√Æner le mod√®le.
4. **Mod√®le d'apprentissage** : r√©seau de neurones (DQN) ou table de Q-Learning.
5. **API de communication** : permet au backend d'interagir avec l'IA.

## **Installation et Configuration**
### **Pr√©requis**
Assurez-vous d'avoir Python install√© ainsi que les d√©pendances n√©cessaires :
```bash
pip install numpy torch gym fastapi uvicorn
```

### **Lancer l'IA en mode entra√Ænement**
```bash
python train.py
```

### **Lancer l'IA en mode jeu**
```bash
python play.py
```

## **Modes de Fonctionnement**
### **1. Entra√Ænement**
- L'IA joue des milliers de parties contre elle-m√™me.
- Elle met √† jour ses poids de r√©seau neuronal en fonction des r√©sultats.
- Elle ajuste ses d√©cisions gr√¢ce √† la fonction de r√©compense.

### **2. Mode de Jeu**
- L'IA re√ßoit un √©tat de la grille et choisit un coup optimal selon sa politique d'action.
- L'API envoie le coup s√©lectionn√© au backend.

## **Fonctionnement de l'algorithme**
### **Q-Learning / DQN**
L'agent suit le cycle :
1. **Observer** l'√©tat actuel de la grille.
2. **S√©lectionner une action** en fonction d'une politique d'exploration/exploitation (Œµ-greedy).
3. **Appliquer l'action** et observer la r√©compense.
4. **Mettre √† jour la valeur Q** pour apprendre du r√©sultat.
5. **R√©p√©ter le processus** jusqu'√† convergence.

## **API REST (Facultatif)**
Si l'IA expose une API pour le backend :
### **Endpoint : Jouer un coup**
```http
POST /play
```
**Payload :**
```json
{
  "grid": [[0,0,0,0,0,0,0],
           [0,0,0,0,0,0,0],
           [0,0,0,0,0,0,0],
           [0,0,0,0,0,0,0],
           [0,0,0,0,0,0,0],
           [0,0,0,1,2,0,0]]
}
```
**R√©ponse :**
```json
{
  "move": 3
}
```

## **Am√©liorations Futures**
- Impl√©mentation de **Monte Carlo Tree Search (MCTS)** pour am√©liorer la prise de d√©cision.
- Ajout d‚Äôun **mode de difficult√© ajustable**.
- Optimisation des performances d‚Äôapprentissage.

---

üöÄ **L'IA Apprentissage est pr√™te √† √©voluer !**

